{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranked Retrieval Coursework by RahmanMT\n",
    "\n",
    "\n",
    "## Introduction\n",
    "This ranked retrival process uses tf_idf to score every term_document pair. \n",
    "breif overview:\n",
    "1. Index the documents' terms and create a postings list containing every document terms and it's tf_idf score\n",
    "2. Convert query into a vector and assign every term a tf_idf score\n",
    "3. Calculate cosine(query,document) for all documents, cosine angle is calculated by a.b/|a|.|b|\n",
    "4. Order the results in descending order and retrive top n results (default n=10)\n",
    "5. Display results\n",
    "\n",
    "## Code\n",
    "\n",
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import operator\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create class and class variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Retrieval:\n",
    "    documents = []   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `documents` list will contain the strings for all the documents, this is to reduce the number of read operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_frequency = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `document_frequency` dict will contain all the terms and it's corresponding inverse document frequency score. Due to repeating terms using a dict will be faster than calculating the document frequency everytime it is required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DOCS = \"bbcsport/docs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PATH_TO_DOCS` is just a string representation of the path to the folder containing the documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postings = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an empty postings dict so that it can be accessed throughout the class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path, docid):       \n",
    "    files = sorted(os.listdir(path))\n",
    "    f = open(os.path.join(path, files[docid]), 'r', encoding='latin-1')\n",
    "    s = f.read()\n",
    "    f.close()\n",
    "    return s.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns the requested document in a string format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "    DELIM = '[ \\n\\t0123456789;:.,/\\(\\)\\\"\\'-]+'\n",
    "    tokens = re.split(DELIM, string.lower())\n",
    "    if '' in tokens:\n",
    "        # Removes any empty strings\n",
    "        tokens.remove('')\n",
    "    # Remove duplicates and return\n",
    "    return list(dict.fromkeys(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizes the input string by normalising and removing duplicates\n",
    "Normalize by removing capitals and removing commas an delimiters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "@staticmethod\n",
    "def calculate_term_freq(token, doc):     \n",
    "    return doc.count(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculates the number of times the token appears in the document string, since it makes no changes to the class it is static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_doc_freq(self, token, N, ):     \n",
    "        # Check if token idf has already been calculated before\n",
    "        if token in self.document_frequency:\n",
    "            return self.document_frequency[token]\n",
    "        else:\n",
    "            # calculate document frequency\n",
    "            df = 0\n",
    "            for doc in self.documents:\n",
    "                if token in doc:\n",
    "                    df += 1\n",
    "            idf = math.log(N / df, 10)\n",
    "            # Store idf score to speed up process for high frequency terms\n",
    "            self.document_frequency.setdefault(token, idf)\n",
    "        return idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculates the document frequency for a given term (idf).The rarer the term, the higher the score. Since there are many re-occuring terms, they are stored in a dict to reduce processing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@staticmethod\n",
    "def calculate_vector_norm(vector):\n",
    "    n = 0\n",
    "    for key, value in vector.items():\n",
    "        n += value ** 2\n",
    "    norm = math.sqrt(n)\n",
    "    return norm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculates the norm of a vector (also known as the magnitude).\n",
    "Since these vectors will have very high number of dimensions, I used a loop to square all the values and sum them before square rooting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2normalize(self, docVectors):        \n",
    "    # find norm\n",
    "    norm = self.calculate_vector_norm(docVectors)\n",
    "    # normalize lengths of vectors\n",
    "    for key, value in docVectors.items():\n",
    "        docVectors[key] = value / norm\n",
    "    return docVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses the norm to normalize the given vectors by dividing each vector by the norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def cosine(self, a, b):\n",
    "        # calculate dot product\n",
    "        dot_product = np.dot(list(a.values()), list(b.values()))\n",
    "        # calculate magnitude of a and b\n",
    "        a_magnitude = self.calculate_vector_norm(a)\n",
    "        b_magnitude = self.calculate_vector_norm(b)\n",
    "        return dot_product / (a_magnitude * b_magnitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculates the cosine of the angle between two given vectors, a and b. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize documents and document document_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_documents(self, path):        \n",
    "    N = len(sorted(os.listdir(path)))\n",
    "    for docID in range(N):\n",
    "        s = self.read_file(path, docID)\n",
    "        self.documents.append(s)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reads all the documents and stores them in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_doc_freq(self, N):\n",
    "    for docID in range(N):\n",
    "        s = self.documents[docID]\n",
    "        tokens = self.tokenize(s)\n",
    "        for t in tokens:\n",
    "            self.calculate_doc_freq(t, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loops through all the documents, for each document it tokenises the terms. Then for each token it calculates the document frequency score and stores the token and score in the `document_frequency` dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing documents for Ranked Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_text_files_rr(self, path):\n",
    "    N = len(sorted(os.listdir(path)))    \n",
    "    postings = {}\n",
    "    for docID in range(N):\n",
    "        s = self.documents[docID]\n",
    "        tokens = self.tokenize(s)\n",
    "        # Create a template using the keys of the document_frequency dict\n",
    "        # This will ensure that all doc vectors have same dimensions\n",
    "        document_data = dict.fromkeys(self.document_frequency, 0)\n",
    "        for t in tokens:\n",
    "            # calculate the relevancy score using tf*idf\n",
    "            tf_idf = self.calculate_term_freq(t, s) * self.document_frequency[t]\n",
    "            # insert tf_idf score to corresponding terms in dict\n",
    "            document_data[t] = tf_idf            \n",
    "        # Normalize the document scores\n",
    "        normalized_data = self.l2normalize(document_data)\n",
    "        postings.setdefault(docID, normalized_data)\n",
    "    return postings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates the postings list for ranked retrieva. The `document_data` is created using the keys from the document_frequency dict so that all the documents have the same dimensions. the postings looks like:\n",
    "{0: {mccall: 0.23452, england: 0.12980374, something: 0.0} 1: {mccall: 0.0, ...} ..}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Query for Ranked Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_rr(self, query, max_results=10):\n",
    "    tokens = self.tokenize(query)\n",
    "    # Create dict with zeros\n",
    "    tf_idf = dict.fromkeys(self.document_frequency, 0)\n",
    "    for t in tokens:\n",
    "        # insert idf scores for tokens, tf scores not needed as it will be 1\n",
    "        tf_idf[t] = self.document_frequency[t]\n",
    "    cosine_scores = {}\n",
    "    for key, value in self.postings.items():\n",
    "        cosine_scores.setdefault(key, self.cosine(tf_idf, value))\n",
    "    # Sort in descending order to get top results\n",
    "    result = OrderedDict(sorted(cosine_scores.items(), key=operator.itemgetter(1), reverse=True)[:max_results])\n",
    "    return result.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly tokenize the query. Then for each token get the corresponding idf score and insert it in the tf_idf list. Since there is only unique tokens each token/word will only have a frequency of 1 and thus we do not need to calculate the term frequency score.\n",
    "Next is to calculate the cosine(query,document) value for every document and order it in descending order, so most relevant document is at the begining.\n",
    "Lastly the function returns the keys of the list for printing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Putting it together in the constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def __init__(self):\n",
    "        self.initialize_documents(self.PATH_TO_DOCS)\n",
    "        self.initialize_doc_freq(len(self.documents))\n",
    "        self.postings = self.index_text_files_rr(self.PATH_TO_DOCS)\n",
    "        # Boolean retrieval code below\n",
    "        #self.index_text_files_br(self.PATH_TO_DOCS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The constructor initializes the postings list and the other relevant data structures used in indexing the documents. The commented code is to initialize the Boolean retrieval postings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval = Retrieval()\n",
    "print(retrieval.query_rr('england mccall united'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use, create a `Retrieval` object and call the `query_rr` passing in a string as a query. The output of the above query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0, 629, 139, 490, 365, 85, 434, 590, 132, 378]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
