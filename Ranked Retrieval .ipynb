{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranked Retrieval Coursework by RahmanMT\n",
    "\n",
    "\n",
    "## Introduction\n",
    "This ranked retrival process uses tf_idf to score every term_document pair. \n",
    "breif overview:\n",
    "1. Index the documents' terms and create a postings list containing every document terms and it's tf_idf score\n",
    "2. Convert query into a vector and assign every term a tf_idf score\n",
    "3. Calculate cosine(query,document) for all documents, cosine angle is calculated by a.b/|a|.|b|\n",
    "4. Order the results in descending order and retrive top n results (default n=10)\n",
    "5. Display results\n",
    "\n",
    "## Code\n",
    "\n",
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import operator\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create class and class variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Retrieval:\n",
    "    documents = []   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `documents` list will contain the strings for all the documents, this is to reduce the number of read operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_frequency = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `document_frequency` dict will contain all the terms and it's corresponding inverse document frequency score. Due to repeating terms using a dict will be faster than calculating the document frequency everytime it is required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DOCS = \"bbcsport/docs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PATH_TO_DOCS` is just a string representation of the path to the folder containing the documents. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path, docid):       \n",
    "    files = sorted(os.listdir(path))\n",
    "    f = open(os.path.join(path, files[docid]), 'r', encoding='latin-1')\n",
    "    s = f.read()\n",
    "    f.close()\n",
    "    return s.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns the requested document in a string format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "    DELIM = '[ \\n\\t0123456789;:.,/\\(\\)\\\"\\'-]+'\n",
    "    tokens = re.split(DELIM, string.lower())\n",
    "    if '' in tokens:\n",
    "        # Removes any empty strings\n",
    "        tokens.remove('')\n",
    "    # Remove duplicates and return\n",
    "    return list(dict.fromkeys(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizes the input string by normalising and removing duplicates\n",
    "Normalize by removing capitals and removing commas an delimiters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "@staticmethod\n",
    "def calculate_term_freq(token, doc):     \n",
    "    return doc.count(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculates the number of times the token appears in the document string, since it makes no changes to the class it is static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_doc_freq(self, token, N, ):     \n",
    "        # Check if token idf has already been calculated before\n",
    "        if token in self.document_frequency:\n",
    "            return self.document_frequency[token]\n",
    "        else:\n",
    "            # calculate document frequency\n",
    "            df = 0\n",
    "            for doc in self.documents:\n",
    "                if token in doc:\n",
    "                    df += 1\n",
    "            idf = math.log(N / df, 10)\n",
    "            # Store idf score to speed up process for high frequency terms\n",
    "            self.document_frequency.setdefault(token, idf)\n",
    "        return idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculates the document frequency for a given term (idf).The rarer the term, the higher the score. Since there are many re-occuring terms, they are stored in a dict to reduce processing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@staticmethod\n",
    "def calculate_vector_norm(vector):\n",
    "    n = 0\n",
    "    for key, value in vector.items():\n",
    "        n += value ** 2\n",
    "    norm = math.sqrt(n)\n",
    "    return norm"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculates the norm of a vector (also known as the magnitude). The Norm is calculated as follows:\n",
    "![image.png](attachment:image.png)\n",
    "Since these vectors will have very high number of dimensions, I used a loop to square all the values and sum them before sqaure rooting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2normalize(self, docVectors):        \n",
    "    # find norm\n",
    "    norm = self.calculate_vector_norm(docVectors)\n",
    "    # normalize lengths of vectors\n",
    "    for key, value in docVectors.items():\n",
    "        docVectors[key] = value / norm\n",
    "    return docVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses the norm to normalize the given vectors by dividing each vector by the norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize documents and document document_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_documents(self, path):        \n",
    "    N = len(sorted(os.listdir(path)))\n",
    "    for docID in range(N):\n",
    "        s = self.read_file(path, docID)\n",
    "        self.documents.append(s)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reads all the documents and stores them in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_doc_freq(self, N):\n",
    "    for docID in range(N):\n",
    "        s = self.documents[docID]\n",
    "        tokens = self.tokenize(s)\n",
    "        for t in tokens:\n",
    "            self.calculate_doc_freq(t, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loops through all the documents, for each document it tokenises the terms. Then for each token it calculates the document frequency score and stores the token and score in the `document_frequency` dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing documents for Ranked Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_text_files_rr(self, path):\n",
    "    N = len(sorted(os.listdir(path)))\n",
    "    self.initialize_doc_freq(N)\n",
    "    postings = {}\n",
    "    for docID in range(N):\n",
    "        s = self.documents[docID]\n",
    "        tokens = self.tokenize(s)\n",
    "        # Create a template using the keys of the document_frequency dict\n",
    "        # This will ensure that all doc vectors have same dimensions\n",
    "        row_data = dict.fromkeys(self.document_frequency, 0)\n",
    "        for t in tokens:\n",
    "            # calculate the relevancy score using tf*idf\n",
    "            tf_idf = self.calculate_term_freq(t, s) * self.document_frequency[t]\n",
    "            # insert tf_idf score to corresponding terms in dict\n",
    "            row_data[t] = tf_idf            \n",
    "        # Normalize the document scores\n",
    "        normalized_data = self.l2normalize(row_data)\n",
    "        postings.setdefault(docID, normalized_data)\n",
    "    return postings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates the postings list for ranked retrieval, the postings looks like:\n",
    "{0: {mccall: 0.23452, england: 0.12980374, something: 0.0} 1: {mccall: 0.0, ...} ..}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
